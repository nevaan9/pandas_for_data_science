{"cells":[{"cell_type":"markdown","id":"CHpJ5pcb0xaC","metadata":{"id":"CHpJ5pcb0xaC"},"source":["<div style=\"color:#006666; padding:0px 10px; border-radius:5px; font-size:18px;\"><h1 style='margin:10px 5px'>Grouping and Aggregation</h1>\n","</div>\n","\n","Â© Copyright Machine Learning Plus"]},{"cell_type":"markdown","id":"QU8gbtBp0xaE","metadata":{"id":"QU8gbtBp0xaE"},"source":["<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>1. GroupBy Mechanism: Split-Apply-Combine</h2>\n","</div>"]},{"cell_type":"markdown","id":"vN241ChB0xaF","metadata":{"id":"vN241ChB0xaF"},"source":["Grouping and aggregation is a very useful technique in data analysis.\n","\n","__When to use__\n","\n","Let's suppose you have a categorical variable (`Class`) and a numerical variable (`Fare`). And you want to know the mean fare for each job type. \n","\n","You can use this, when you have more than one categorical (and numerical) variable as well."]},{"cell_type":"markdown","id":"vsEQ85n30xaG","metadata":{"id":"vsEQ85n30xaG"},"source":["__How it works:__ \n","\n","__Split -> Apply -> Combine__"]},{"cell_type":"code","execution_count":null,"id":"rwXuNgV00xaG","metadata":{"id":"rwXuNgV00xaG"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"4_TLzYgR0xaH","metadata":{"id":"4_TLzYgR0xaH","outputId":"08eb9bbe-9aac-4bf5-a3d0-660d6f6f351b","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('Datasets/Titanic.csv')\n","df.head()"]},{"cell_type":"markdown","id":"KWszK6wY0xaI","metadata":{"id":"KWszK6wY0xaI"},"source":["__Task__\n","\n","Compute the mean survival rate for each Class (`Pclass`)"]},{"cell_type":"code","execution_count":null,"id":"7EftIjOT0xaJ","metadata":{"id":"7EftIjOT0xaJ","outputId":"3c4036bb-5a66-4c6e-c2d7-45dab3d720f6","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","    </tr>\n","    <tr>\n","      <th>Pclass</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.629630</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.472826</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.242363</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Survived\n","Pclass          \n","1       0.629630\n","2       0.472826\n","3       0.242363"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby('Pclass').agg({'Survived': np.mean})"]},{"cell_type":"markdown","id":"7pbs9r-e0xaJ","metadata":{"id":"7pbs9r-e0xaJ"},"source":["Clearly, Class 1 gets more priority followed by class 2."]},{"cell_type":"markdown","id":"_pDIyuMs0xaK","metadata":{"id":"_pDIyuMs0xaK"},"source":["Compute the total persons survived in each class as well."]},{"cell_type":"code","execution_count":null,"id":"ZQbFinRd0xaK","metadata":{"id":"ZQbFinRd0xaK","outputId":"ca2ce497-2bdf-4290-9a63-2d7ed657e565"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"2\" halign=\"left\">Survived</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>mean</th>\n","      <th>sum</th>\n","    </tr>\n","    <tr>\n","      <th>Pclass</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.629630</td>\n","      <td>136</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.472826</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.242363</td>\n","      <td>119</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Survived     \n","            mean  sum\n","Pclass               \n","1       0.629630  136\n","2       0.472826   87\n","3       0.242363  119"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby('Pclass').agg({'Survived': [np.mean, np.sum]})"]},{"cell_type":"markdown","id":"cXIdJDTm0xaL","metadata":{"id":"cXIdJDTm0xaL"},"source":["And more people from class 1 were saved."]},{"cell_type":"markdown","id":"1iLqeZkS0xaL","metadata":{"id":"1iLqeZkS0xaL"},"source":["Groupby `sex` as well"]},{"cell_type":"code","execution_count":null,"id":"mzzK1LQF0xaL","metadata":{"id":"mzzK1LQF0xaL","outputId":"2aff3224-c84b-4cf1-a643-2f2b27056552","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"2\" halign=\"left\">Survived</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>mean</th>\n","      <th>sum</th>\n","    </tr>\n","    <tr>\n","      <th>Sex</th>\n","      <th>Pclass</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">female</th>\n","      <th>1</th>\n","      <td>0.968085</td>\n","      <td>91</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.921053</td>\n","      <td>70</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.500000</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">male</th>\n","      <th>1</th>\n","      <td>0.368852</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.157407</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.135447</td>\n","      <td>47</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Survived    \n","                   mean sum\n","Sex    Pclass              \n","female 1       0.968085  91\n","       2       0.921053  70\n","       3       0.500000  72\n","male   1       0.368852  45\n","       2       0.157407  17\n","       3       0.135447  47"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby(['Sex', 'Pclass']).agg({'Survived': [np.mean, np.sum]})"]},{"cell_type":"markdown","id":"CEHOqNPh0xaM","metadata":{"id":"CEHOqNPh0xaM"},"source":["Within the classes, Female seem to have got more priority consistently across classes."]},{"cell_type":"markdown","id":"nOOmsP590xaM","metadata":{"id":"nOOmsP590xaM"},"source":["That's clear, how about writing custom functions instead of standard functions like 'mean' and 'sum'?\n","\n","Just define the function and use it."]},{"cell_type":"markdown","id":"gCgQLH_t0xaM","metadata":{"id":"gCgQLH_t0xaM"},"source":["__To make the index as columns use `reset_index()`___"]},{"cell_type":"code","execution_count":null,"id":"xdwcuQ3u0xaM","metadata":{"id":"xdwcuQ3u0xaM","outputId":"6888d869-5278-47a4-be3f-b5b17ceacd94"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th>Sex</th>\n","      <th>Pclass</th>\n","      <th colspan=\"2\" halign=\"left\">Survived</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>mean</th>\n","      <th>sum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>female</td>\n","      <td>1</td>\n","      <td>0.968085</td>\n","      <td>91</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>2</td>\n","      <td>0.921053</td>\n","      <td>70</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>female</td>\n","      <td>3</td>\n","      <td>0.500000</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>male</td>\n","      <td>1</td>\n","      <td>0.368852</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>male</td>\n","      <td>2</td>\n","      <td>0.157407</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>male</td>\n","      <td>3</td>\n","      <td>0.135447</td>\n","      <td>47</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Sex Pclass  Survived    \n","                      mean sum\n","0  female      1  0.968085  91\n","1  female      2  0.921053  70\n","2  female      3  0.500000  72\n","3    male      1  0.368852  45\n","4    male      2  0.157407  17\n","5    male      3  0.135447  47"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby(['Sex', 'Pclass']).agg({'Survived': [np.mean, np.sum]}).reset_index()"]},{"cell_type":"markdown","id":"KgQM5pUF0xaM","metadata":{"id":"KgQM5pUF0xaM"},"source":["__Task__\n","\n","Find the difference of the maximum and the minimum fare paid by each class."]},{"cell_type":"code","execution_count":null,"id":"7AqPtZ8i0xaN","metadata":{"id":"7AqPtZ8i0xaN","outputId":"d1474f4c-7aaf-414c-852c-3fa912849d6e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fare</th>\n","    </tr>\n","    <tr>\n","      <th>Pclass</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>512.3292</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>73.5000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>69.5500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Fare\n","Pclass          \n","1       512.3292\n","2        73.5000\n","3        69.5500"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby('Pclass').agg({'Fare': lambda x: np.max(x) - np.min(x)})"]},{"cell_type":"markdown","id":"lEHBj2Hj0xaN","metadata":{"id":"lEHBj2Hj0xaN"},"source":["Show the max, min. And groupby Sex as well."]},{"cell_type":"code","execution_count":null,"id":"JuS1Lkqe0xaN","metadata":{"id":"JuS1Lkqe0xaN","outputId":"4a7d505e-d717-4463-db26-090324eec270"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">Fare</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>amin</th>\n","      <th>amax</th>\n","      <th>minmax</th>\n","    </tr>\n","    <tr>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">1</th>\n","      <th>female</th>\n","      <td>25.9292</td>\n","      <td>512.3292</td>\n","      <td>486.4000</td>\n","    </tr>\n","    <tr>\n","      <th>male</th>\n","      <td>0.0000</td>\n","      <td>512.3292</td>\n","      <td>512.3292</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">2</th>\n","      <th>female</th>\n","      <td>10.5000</td>\n","      <td>65.0000</td>\n","      <td>54.5000</td>\n","    </tr>\n","    <tr>\n","      <th>male</th>\n","      <td>0.0000</td>\n","      <td>73.5000</td>\n","      <td>73.5000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">3</th>\n","      <th>female</th>\n","      <td>6.7500</td>\n","      <td>69.5500</td>\n","      <td>62.8000</td>\n","    </tr>\n","    <tr>\n","      <th>male</th>\n","      <td>0.0000</td>\n","      <td>69.5500</td>\n","      <td>69.5500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Fare                    \n","                  amin      amax    minmax\n","Pclass Sex                                \n","1      female  25.9292  512.3292  486.4000\n","       male     0.0000  512.3292  512.3292\n","2      female  10.5000   65.0000   54.5000\n","       male     0.0000   73.5000   73.5000\n","3      female   6.7500   69.5500   62.8000\n","       male     0.0000   69.5500   69.5500"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["def minmax(x): \n","    return np.max(x) - np.min(x)\n","    \n","df.groupby(['Pclass', 'Sex']).agg({'Fare': [np.min, np.max, minmax]})"]},{"cell_type":"markdown","id":"8HSnU3hr0xaN","metadata":{"id":"8HSnU3hr0xaN"},"source":["So, there are people who paid nothing to get onboard and these were all men."]},{"cell_type":"markdown","id":"dzcq2bQG0xaO","metadata":{"id":"dzcq2bQG0xaO"},"source":["### Mini Challege\n","\n","Compute correlation between 'Survived' and 'Fare' grouped by `Pclass`.\n","\n","```python\n","import pandas as pd\n","df = pd.read_csv('Datasets/Titanic.csv')\n","df.head()\n","```"]},{"cell_type":"markdown","id":"YYAzUed00xaO","metadata":{"id":"YYAzUed00xaO"},"source":["__Solution:__"]},{"cell_type":"code","execution_count":null,"id":"2s9pwjqv0xaO","metadata":{"id":"2s9pwjqv0xaO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b6Kgonxk0xaO","metadata":{"id":"b6Kgonxk0xaO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"XojGIx_w0xaO","metadata":{"id":"XojGIx_w0xaO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9MXZvJMY0xaO","metadata":{"id":"9MXZvJMY0xaO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"k-qhY46J0xaO","metadata":{"id":"k-qhY46J0xaO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"RLjbHym20xaO","metadata":{"id":"RLjbHym20xaO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"l_ntiWyH0xaO","metadata":{"id":"l_ntiWyH0xaO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"GJ_mjUqC0xaP","metadata":{"id":"GJ_mjUqC0xaP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"UeBvhxK90xaP","metadata":{"id":"UeBvhxK90xaP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"CaIeaG9y0xaP","metadata":{"id":"CaIeaG9y0xaP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"1cUW6ts_0xaP","metadata":{"id":"1cUW6ts_0xaP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Iv8JljdR0xaP","metadata":{"id":"Iv8JljdR0xaP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Jt_DUwVt0xaP","metadata":{"id":"Jt_DUwVt0xaP"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"_-KoN2Do0xaP","metadata":{"id":"_-KoN2Do0xaP","outputId":"257de68c-7eb3-4d0a-a1b9-90479db09f19"},"outputs":[{"name":"stdout","output_type":"stream","text":["              Fare  Survived\n","Fare      1.000000  0.190966\n","Survived  0.190966  1.000000\n","              Fare  Survived\n","Fare      1.000000  0.098628\n","Survived  0.098628  1.000000\n","             Fare  Survived\n","Fare      1.00000   0.00093\n","Survived  0.00093   1.00000\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# Get Groupwise correlations\n","df = pd.read_csv('Datasets/Titanic.csv')\n","df.groupby('Pclass').apply(lambda x: print(x[['Fare', 'Survived']].corr()))"]},{"cell_type":"code","execution_count":null,"id":"_3KyOA8L0xaP","metadata":{"id":"_3KyOA8L0xaP","outputId":"52ab71b7-a5a3-4436-f995-51a8e62589c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.19096640841564308\n","0.09862818081146572\n","0.0009295304523811009\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# Get only the correlation values\n","df.groupby('Pclass').apply(lambda x: print(x[['Fare', 'Survived']].corr().iloc[0,1]))"]},{"cell_type":"markdown","id":"Huic7JPA0xaQ","metadata":{"id":"Huic7JPA0xaQ"},"source":["<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>2. Iterating over Groups</h2>\n","</div>"]},{"cell_type":"markdown","id":"0-GzZztw0xaQ","metadata":{"id":"0-GzZztw0xaQ"},"source":["Doing a `groupby` on a dataframe, creates an iterable DataFrameGroupby object.\n","\n","If you want to do further do customized operations, you can iterate through the groups and do it.\n","\n","For example: You want to compute the mean fare for every class, but you want to omit all zero fares for Male passengers in the 2nd class alone.\n","\n","For such customized logic, iterating through the groups makes it easy.\n"]},{"cell_type":"code","execution_count":null,"id":"KIZn4tSP0xaQ","metadata":{"id":"KIZn4tSP0xaQ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"eAJ6PHTG0xaQ","metadata":{"id":"eAJ6PHTG0xaQ","outputId":"e73181b5-9415-4557-d831-6ca08d9208b7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('Datasets/Titanic.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"id":"36PM9PSc0xaR","metadata":{"id":"36PM9PSc0xaR","outputId":"e4550285-ee5c-4ca3-8470-019a10da5c33"},"outputs":[{"data":{"text/plain":["<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000017C0EC27A88>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df_groups = df.groupby('Pclass')\n","df_groups"]},{"cell_type":"markdown","id":"gW_vmNiM0xaR","metadata":{"id":"gW_vmNiM0xaR"},"source":["Let's look at the data in each group."]},{"cell_type":"code","execution_count":null,"id":"_Zeqz39q0xaR","metadata":{"id":"_Zeqz39q0xaR","outputId":"ab452355-1bdb-4c54-b474-c75a3da14826"},"outputs":[{"name":"stdout","output_type":"stream","text":["Group name:  1\n","   PassengerId  Survived  Pclass  \\\n","1            2         1       1   \n","3            4         1       1   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","\n","   Parch    Ticket     Fare Cabin Embarked  \n","1      0  PC 17599  71.2833   C85        C  \n","3      0    113803  53.1000  C123        S   \n","\n","\n","Group name:  2\n","    PassengerId  Survived  Pclass                                 Name  \\\n","9            10         1       2  Nasser, Mrs. Nicholas (Adele Achem)   \n","15           16         1       2     Hewlett, Mrs. (Mary D Kingcome)    \n","\n","       Sex   Age  SibSp  Parch  Ticket     Fare Cabin Embarked  \n","9   female  14.0      1      0  237736  30.0708   NaN        C  \n","15  female  55.0      0      0  248706  16.0000   NaN        S   \n","\n","\n","Group name:  3\n","   PassengerId  Survived  Pclass                     Name     Sex   Age  \\\n","0            1         0       3  Braund, Mr. Owen Harris    male  22.0   \n","2            3         1       3   Heikkinen, Miss. Laina  female  26.0   \n","\n","   SibSp  Parch            Ticket   Fare Cabin Embarked  \n","0      1      0         A/5 21171  7.250   NaN        S  \n","2      0      0  STON/O2. 3101282  7.925   NaN        S   \n","\n","\n"]}],"source":["# Group the dataframe by Pclass\n","for name, group in df.groupby('Pclass'): \n","    print(\"Group name: \", name)\n","    print(group.head(2), \"\\n\\n\")\n"]},{"cell_type":"markdown","id":"vjdF1UVq0xaR","metadata":{"id":"vjdF1UVq0xaR"},"source":["Writing the logic"]},{"cell_type":"code","execution_count":null,"id":"5ZJd4PLQ0xaR","metadata":{"id":"5ZJd4PLQ0xaR","outputId":"ab3d8bc0-340d-433e-dbb3-9e1e3d0c7ac2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Group name:  1\n","84.15\n","Group name:  2\n","20.66\n","Group name:  3\n","13.68\n"]}],"source":["# Group the dataframe by Pclass\n","for name, group in df.groupby('Pclass'): \n","    print(\"Group name: \", name)\n","    if name == 2:\n","        print(group.loc[(group.Sex!=\"male\") & (group.Fare!=0), \"Fare\"].mean().round(2))\n","        # print(group.Fare.mean().round(2))\n","    else:\n","        print(group.Fare.mean().round(2))"]},{"cell_type":"markdown","id":"3Mode_Qo0xaR","metadata":{"id":"3Mode_Qo0xaR"},"source":["### Challenge\n","\n","Do a groupby operation on the Titanic dataframe on `Pclass`. Iterate through each group and extract the names of top three female passengers who paid the highest fare."]},{"cell_type":"code","execution_count":null,"id":"0eU4CQ830xaR","metadata":{"id":"0eU4CQ830xaR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"SHhvCo6_0xaS","metadata":{"id":"SHhvCo6_0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"jPNSFTxy0xaS","metadata":{"id":"jPNSFTxy0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"IQi8lDko0xaS","metadata":{"id":"IQi8lDko0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"p85-f69W0xaS","metadata":{"id":"p85-f69W0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"GRs6q4mt0xaS","metadata":{"id":"GRs6q4mt0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0t4_6y_00xaS","metadata":{"id":"0t4_6y_00xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ppRN6nYE0xaS","metadata":{"id":"ppRN6nYE0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"WOuitlHE0xaS","metadata":{"id":"WOuitlHE0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4KlDCAku0xaS","metadata":{"id":"4KlDCAku0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"B5MrvZE_0xaS","metadata":{"id":"B5MrvZE_0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"_HPFGeLH0xaS","metadata":{"id":"_HPFGeLH0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"W8Ua0W0q0xaS","metadata":{"id":"W8Ua0W0q0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"w3RTDSpN0xaS","metadata":{"id":"w3RTDSpN0xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"7WMoInB30xaS","metadata":{"id":"7WMoInB30xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"dwjF7TP80xaS","metadata":{"id":"dwjF7TP80xaS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"jRIYbQQO0xaT","metadata":{"id":"jRIYbQQO0xaT","outputId":"004dc6aa-9925-4eee-f36a-400e843d588b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Group name:  1\n","                               Name      Fare\n","258                Ward, Miss. Anna  512.3292\n","88       Fortune, Miss. Mabel Helen  263.0000\n","341  Fortune, Miss. Alice Elizabeth  263.0000 \n","\n","\n","Group name:  2\n","                                                  Name     Fare\n","615                                Herman, Miss. Alice  65.0000\n","754                   Herman, Mrs. Samuel (Jane Laver)  65.0000\n","608  Laroche, Mrs. Joseph (Juliette Marie Louise La...  41.5792 \n","\n","\n","Group name:  3\n","                                  Name   Fare\n","792            Sage, Miss. Stella Anna  69.55\n","180       Sage, Miss. Constance Gladys  69.55\n","863  Sage, Miss. Dorothy Edith \"Dolly\"  69.55 \n","\n","\n"]}],"source":["# Solution ---\n","# Group the dataframe by Pclass\n","for name, group in df.groupby('Pclass'): \n","    print(\"Group name: \", name)\n","    group = group.sort_values('Fare', ascending=False)\n","    print(group.loc[group.Sex==\"female\", [\"Name\", \"Fare\"]].head(3), \"\\n\\n\")"]},{"cell_type":"code","execution_count":null,"id":"v7vTCNkK0xaT","metadata":{"id":"v7vTCNkK0xaT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"-KNlZe7U0xaT","metadata":{"id":"-KNlZe7U0xaT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"I0fpwl-m0xaT","metadata":{"id":"I0fpwl-m0xaT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"RE7q65C-0xaT","metadata":{"id":"RE7q65C-0xaT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fjtLv9Kp0xaT","metadata":{"id":"fjtLv9Kp0xaT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"mw2JQTen0xaT","metadata":{"id":"mw2JQTen0xaT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"Ms-H1L-a0xaT","metadata":{"id":"Ms-H1L-a0xaT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fgpPw-BT0xaT","metadata":{"id":"fgpPw-BT0xaT"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"RqWR3rk90xaT","metadata":{"id":"RqWR3rk90xaT"},"source":["<div class=\"alert alert-info\" style=\"background-color:#006666; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>3. Transform Method</h2>\n","</div>"]},{"cell_type":"markdown","id":"LntSD6ZG0xaT","metadata":{"id":"LntSD6ZG0xaT"},"source":["__When to use__\n","\n","Sometimes instead of aggregating based on a groupby column, you want to create an entirely new column.\n","\n","__Example Task__: \n","\n","In Titanic data, you want to create a new column that contains the mean fare for that class."]},{"cell_type":"code","execution_count":null,"id":"r8QAZQ-A0xaU","metadata":{"id":"r8QAZQ-A0xaU"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"HgyX7rlw0xaU","metadata":{"id":"HgyX7rlw0xaU","outputId":"c01b49fd-4adb-469e-a239-f0d564e631d1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('Datasets/Titanic.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"id":"XkEgLxzz0xaU","metadata":{"id":"XkEgLxzz0xaU"},"outputs":[],"source":["df[\"Fare_Mean\"] = df.groupby('Pclass')[\"Fare\"].transform('mean')"]},{"cell_type":"code","execution_count":null,"id":"YsgECJ7o0xaU","metadata":{"id":"YsgECJ7o0xaU","outputId":"9108aba3-a90b-4548-a243-7241fa874593"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>Fare_Mean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>13.675550</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","      <td>84.154687</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>13.675550</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","      <td>84.154687</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>13.675550</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  Fare_Mean  \n","0      0         A/5 21171   7.2500   NaN        S  13.675550  \n","1      0          PC 17599  71.2833   C85        C  84.154687  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  13.675550  \n","3      0            113803  53.1000  C123        S  84.154687  \n","4      0            373450   8.0500   NaN        S  13.675550  "]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","id":"7A2tQ23G0xaU","metadata":{"id":"7A2tQ23G0xaU"},"source":["### Challenge\n","\n","What percentage of total fare in the class, does each individual has contributed?\n","\n","```python\n","df = pd.read_csv('Datasets/Titanic.csv')\n","```"]},{"cell_type":"code","execution_count":null,"id":"xA_ImQ_D0xaU","metadata":{"id":"xA_ImQ_D0xaU","outputId":"c5502946-a848-428c-dfa1-889165aaf52b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>Fare_Class_Total</th>\n","      <th>Fare_Perc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>6714.6951</td>\n","      <td>0.001080</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","      <td>18177.4125</td>\n","      <td>0.003922</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>6714.6951</td>\n","      <td>0.001180</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","      <td>18177.4125</td>\n","      <td>0.002921</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>6714.6951</td>\n","      <td>0.001199</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  Fare_Class_Total  \\\n","0      0         A/5 21171   7.2500   NaN        S         6714.6951   \n","1      0          PC 17599  71.2833   C85        C        18177.4125   \n","2      0  STON/O2. 3101282   7.9250   NaN        S         6714.6951   \n","3      0            113803  53.1000  C123        S        18177.4125   \n","4      0            373450   8.0500   NaN        S         6714.6951   \n","\n","   Fare_Perc  \n","0   0.001080  \n","1   0.003922  \n","2   0.001180  \n","3   0.002921  \n","4   0.001199  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Solution\n","df = pd.read_csv('Datasets/Titanic.csv')\n","\n","\n","df[\"Fare_Class_Total\"] = df.groupby('Pclass')[\"Fare\"].transform('sum')\n","df[\"Fare_Perc\"] = df[\"Fare\"] / df[\"Fare_Class_Total\"]\n","\n","df.head()"]}],"metadata":{"colab":{"collapsed_sections":["dzcq2bQG0xaO","3Mode_Qo0xaR","7A2tQ23G0xaU"],"name":"06_Data Grouping and Aggregation.ipynb","provenance":[]},"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":5}
